{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from main import *\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from pyecharts.options.global_options import InitOpts\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pyecharts\n",
    "import random\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Geo\n",
    "from pyecharts.globals import ChartType, SymbolType, GeoType\n",
    "from shapely.wkb import dumps as b_dumps, loads as b_loads\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import geopandas as gpd\n",
    "import statsmodels.api as sm # recommended import according to the docs\n",
    "import copy\n",
    "from multiprocessing import  Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有论文数据的整合代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_data():\n",
    "    '''alibi'''\n",
    "    #filefolder='/data/chenwei/research3/icnp/data_paper/alibi'\n",
    "    '''alibi的error ratio'''\n",
    "#     with open(f'{filefolder}/Egypt_300_error.txt','w')as f:\n",
    "#         f.write(str(alibi_300_E))\n",
    "#         f.write('\\n')\n",
    "#         f.write(str(sca_alibi_300_E))\n",
    "#     with open(f'{filefolder}/Egypt_600_error.txt','w')as f:\n",
    "#         f.write(str(alibi_600_E))\n",
    "#         f.write('\\n')\n",
    "#         f.write(str(sca_alibi_600_E))\n",
    "#     with open(f'{filefolder}/Korea_300_error.txt','w')as f:\n",
    "#         f.write(str(alibi_300_K))\n",
    "#         f.write('\\n')\n",
    "#         f.write(str(sca_alibi_300_K))\n",
    "#     with open(f'{filefolder}/Korea_600_error.txt','w')as f:\n",
    "#         f.write(str(alibi_600_K))\n",
    "#         f.write('\\n')\n",
    "#         f.write(str(sca_alibi_600_K))\n",
    "    '''alibi的delay inflation'''\n",
    "#     with open(f'{filefolder}/di_Egypt.txt','w')as f:\n",
    "#         f.write(str(di_E_alibi_0))\n",
    "#         f.write('\\n')\n",
    "#         f.write(str(di_E_alibi_05))\n",
    "#     with open(f'{filefolder}/di_Korea.txt','w')as f:\n",
    "#         f.write(str(di_K_alibi_0))\n",
    "#         f.write('\\n')\n",
    "#         f.write(str(di_K_alibi_05))\n",
    "    '''starveri'''\n",
    "    filefolder='/data/chenwei/research3/icnp/data_paper/starveri'\n",
    "#     '''starveri的nlrp & risk sats frequency'''\n",
    "#     with open(f'{filefolder}/nlrp&rs_fre_Egypt_Starlink1.txt','w')as f:\n",
    "#         f.write(f'{str(nlrp0_st)}\\n{str(nlrp1_st)}\\n{str(rs0_st)}\\n{str(rs1_st)}')\n",
    "#     with open(f'{filefolder}/nlrp&rs_fre_Egypt_Kuiper1.txt','w')as f:\n",
    "#         f.write(f'{str(nlrp0_kp)}\\n{str(nlrp1_kp)}\\n{str(rs0_kp)}\\n{str(rs1_kp)}')\n",
    "    '''starveri RAR'''\n",
    "#     with open(f'{filefolder}/rar_Egypt_Starlink1.txt','w')as f:\n",
    "#         f.write(f'{str(theta0_st_E)}\\n{str(theta1_st_E)}')\n",
    "#     with open(f'{filefolder}/rar_Egypt_Kuiper1.txt','w')as f:\n",
    "#         f.write(f'{str(theta0_kp_E)}\\n{str(theta1_kp_E)}')\n",
    "    '''starveri delay inflation'''\n",
    "#     with open(f'{filefolder}/di_Egypt_Starlink1.txt','w')as f:\n",
    "#         f.write(f'{str(delay_E_st_0)}\\n{delay_E_st_1}\\n{delay_E_st_2}\\n')\n",
    "#     with open(f'{filefolder}/dthr_Egypt_Starlink1.txt','w')as f:\n",
    "#         f.write(f'{str(thr_E_st_0)}\\n{thr_E_st_1}\\n{thr_E_st_2}\\n')\n",
    "#     with open(f'{filefolder}/di_Egypt_Kuiper1.txt','w')as f:\n",
    "#         f.write(f'{str(delay_E_kp_0)}\\n{delay_E_kp_1}\\n{delay_E_kp_2}\\n')\n",
    "#     with open(f'{filefolder}/dthr_Egypt_Kuiper1.txt','w')as f:\n",
    "#         f.write(f'{str(thr_E_kp_0)}\\n{thr_E_kp_1}\\n{thr_E_kp_2}\\n')\n",
    "#     with open(f'{filefolder}/di_Korea_Kuiper1.txt','w')as f:\n",
    "#         f.write(f'{str(delay_K_kp_0)}\\n{delay_K_kp_1}\\n{delay_K_kp_2}\\n')\n",
    "#     with open(f'{filefolder}/dthr_Korea_Kuiper1.txt','w')as f:\n",
    "#         f.write(f'{str(thr_K_kp_0)}\\n{thr_K_kp_1}\\n{thr_K_kp_2}\\n')\n",
    "#     with open(f'{filefolder}/di_Korea_Starlink1.txt','w')as f:\n",
    "#         f.write(f'{str(delay_K_st_0)}\\n{delay_K_st_1}\\n{delay_K_st_2}\\n')\n",
    "#     with open(f'{filefolder}/dthr_Korea_Starlink1.txt','w')as f:\n",
    "#         f.write(f'{str(thr_K_st_0)}\\n{thr_K_st_1}\\n{thr_K_st_2}\\n')\n",
    "    '''starveri emulation result'''\n",
    "    with open(f'{filefolder}/emu_result.txt','w')as f:\n",
    "        f.write(f'{str(process_delay_emu)}\\n{str(min_max_process_delay_emu)}')\n",
    "record_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part: Analyze motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Process error ratios of Alibi in different time windows/factors'''\n",
    "def data_process():\n",
    "    step=600\n",
    "    for t in range(198):\n",
    "        fn=0\n",
    "        fp=0\n",
    "        \n",
    "        try:\n",
    "            file=f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Korea/0/{t}_600.txt'\n",
    "            data=eval(open(file,'r').readline())\n",
    "            if os.path.exists(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Korea/data_process/{t}_{step}.txt'):\n",
    "                pass\n",
    "            else:\n",
    "                filew=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Korea/data_process/{t}_{step}.txt','w')\n",
    "                filew2=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Korea/data_process/{t}_300.txt','w')\n",
    "            d=[[0,0]for _ in range(len(data))]\n",
    "            d2=[[0,0]for _ in range(len(data))]\n",
    "            for index,items in enumerate(data):\n",
    "                for info in items:\n",
    "                    fn+=info[4]\n",
    "                    fp+=info[3]\n",
    "                    d[index][0]+=info[3]\n",
    "                    d[index][1]+=info[4]\n",
    "                    if info[0]<index*600+300:\n",
    "                        d2[index][0]+=info[3]\n",
    "                        d2[index][1]+=info[4]\n",
    "            filew.write(str(d))\n",
    "            filew2.write(str(d2))\n",
    "            filew.close()\n",
    "            filew2.close()\n",
    "        except:continue\n",
    "#data_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ana_moti(step,num):\n",
    "    #draw rtt\n",
    "    sd_no=0\n",
    "    import matplotlib as mpl\n",
    "    from matplotlib import cm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    import InterestingColorfulColor as ICC\n",
    "    import json\n",
    "    import random\n",
    "    '''Draw all the city-pairs in 24h'''\n",
    "\n",
    "    fn_all,fp_all=[],[]\n",
    "    \n",
    "        \n",
    "    for t in range(198):\n",
    "        fn=0\n",
    "        fp=0\n",
    "        \n",
    "        try:\n",
    "            file=f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/0/{t}_600.txt'\n",
    "            data=eval(open(file,'r').readline())\n",
    "            if os.path.exists(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/data_process/{t}_{step}.txt'):\n",
    "                pass\n",
    "            else:\n",
    "                filew=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/data_process/{t}_{step}.txt','w')\n",
    "                filew2=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/data_process/{t}_300.txt','w')\n",
    "            d=[[0,0]for _ in range(len(data))]\n",
    "            d2=[[0,0]for _ in range(len(data))]\n",
    "            for index,items in enumerate(data):\n",
    "                for info in items:\n",
    "                    fn+=info[4]\n",
    "                    fp+=info[3]\n",
    "                    d[index][0]+=info[3]\n",
    "                    d[index][1]+=info[4]\n",
    "                    if info[0]<index*600+300:\n",
    "                        d2[index][0]+=info[3]\n",
    "                        d2[index][1]+=info[4]\n",
    "            fn_all.append(fn/num)\n",
    "            fp_all.append(fp/num)\n",
    "            filew.write(str(d))\n",
    "            filew2.write(str(d2))\n",
    "            filew.close()\n",
    "            filew2.close()\n",
    "        except:continue\n",
    "    print(np.mean(fp_all),max(fp_all),min(fp_all),np.mean(fn_all),max(fn_all),min(fn_all))\n",
    "    fig , ax = plt.subplots(figsize=(4, 3))\n",
    "    data=fp_all\n",
    "    ecdf = sm.distributions.ECDF(data)\n",
    "    x = np.linspace(0, max(data))\n",
    "    y = ecdf(x)\n",
    "    plt.plot(x, y, linewidth = 3,ls='--',color='blue',label=f'FP')\n",
    "    data=fn_all\n",
    "    ecdf = sm.distributions.ECDF(data)\n",
    "    x = np.linspace(0, max(data))\n",
    "    y = ecdf(x)\n",
    "    plt.plot(x, y, linewidth = 3,ls='-.',color='orange',label=f'FN')\n",
    "    plt.xlabel('# of errors in 24h',size=18)\n",
    "    plt.ylabel('CDF',size=18)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend( loc='upper left', fontsize = 15)\n",
    "    plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/moti_6000s/fig/motivation_all_error.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "#     file=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/moti_6000s/Egypt/0/{sd_no}/data{step}.txt','r')\n",
    "# #     file=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/0/{sd_no}_600.txt','r')\n",
    "\n",
    "#     data=eval(file.readline())\n",
    "\n",
    "#     plt.rcParams['pdf.fonttype'] = 42 \n",
    "#     fig , ax = plt.subplots(figsize=(5, 3))\n",
    "# #     fig , ax = plt.subplots()\n",
    "#     bench_rtt=[]\n",
    "#     bench_t=[]\n",
    "#     fp_rtt=[]\n",
    "#     fp_t=[]\n",
    "#     fn_rtt=[]\n",
    "#     fn_t=[]\n",
    "#     ave_fp=[]\n",
    "#     ave_fn=[]\n",
    "#     for window in range(len(data)):\n",
    "#         d=data[window]\n",
    "#         fp,fn=0,0\n",
    "#         for ind in range(len(d)):\n",
    "#             if ind==0:\n",
    "#                 ran=random.random()\n",
    "#                 flag=-1\n",
    "#                 if ran<0.5:flag=1\n",
    "#                 ran=random.uniform(0,100)\n",
    "#                 delay=d[ind][1]*2000 if d[ind][1]!=-1 else 500+flag*ran\n",
    "#                 for i in range(step):\n",
    "#                     bench_t.append(window*step+i)\n",
    "#                     bench_rtt.append(delay)\n",
    "#             else:\n",
    "#                 delay=d[ind][2]*2000 if d[ind][2]!=-1 else 500+flag*ran\n",
    "#                 if d[ind][3]==1:\n",
    "#                     fp_rtt.append(delay)\n",
    "#                     fp_t.append(d[ind][0])\n",
    "#                     fp+=1\n",
    "#                 elif d[ind][4]==1:\n",
    "#                     fn_rtt.append(delay)\n",
    "#                     fn_t.append(d[ind][0])\n",
    "#                     fn+=1\n",
    "#         ave_fp.append(fp/step)\n",
    "#         ave_fn.append(fn/step)\n",
    "#     print(len(fp_t)/num,len(fn_t)/num,max(ave_fn),max(ave_fp)) \n",
    "    \n",
    "#     data=eval(open('/data/chenwei/research3/data/result_shortest_gs_alibi/Egypt/0_process/35_600.txt','r').readline())[0:10]\n",
    "#     ave_fp=[]\n",
    "#     ave_fn=[]\n",
    "#     for i in data:\n",
    "#         ave_fp.append(i[0]/600)\n",
    "#         ave_fn.append(i[1]/600)\n",
    "#     ecdf = sm.distributions.ECDF(ave_fp)\n",
    "#     x = np.linspace(0, max(ave_fp))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 1,ls='--',color='blue',label=f'FP')\n",
    "#     ecdf = sm.distributions.ECDF(ave_fn)\n",
    "#     x = np.linspace(0, max(ave_fn))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 1,ls='--',color='orange',label=f'FN')\n",
    "#     plt.xlim(0,1)\n",
    "#     print(np.mean(ave_fp),np.mean(ave_fn))\n",
    "    \n",
    "#     plt.plot(bench_t,bench_rtt,linewidth=0.5,c='blue',label='Bench-RTT')\n",
    "    \n",
    "#     plt.scatter(fp_t,fp_rtt,s=10,c='red',marker='.',label='FP')\n",
    "#     plt.scatter(fn_t,fn_rtt,s=10,c='orange',marker='o',label='FN')\n",
    "#     for _ in range(10):\n",
    "#         plt.plot([_*step,_*step],[0,step],linewidth=0.5,c='black',linestyle=':')\n",
    "    \n",
    "#     plt.xlabel('Time(s)',size=18)\n",
    "#     plt.ylabel('RTT(ms)',size=18)\n",
    "    \n",
    "#     handles, labels = plt.gca().get_legend_handles_labels()\n",
    "#     by_label = dict(zip(labels, handles))\n",
    "#     #plt.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize = 15)\n",
    "#     plt.legend(frameon = False,fontsize=13,bbox_to_anchor=(1, 1), loc='lower right', ncol=3, borderaxespad=0, handletextpad = 0.2, columnspacing = 0.4, labelspacing=0.2)\n",
    "#     plt.xlim(0,6000,step)\n",
    "#     plt.ylim(0,600)\n",
    "#     ax.tick_params(axis='x', labelsize=16)\n",
    "#     ax.tick_params(axis='y', labelsize=16)\n",
    "#     plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/moti_6000s/fig/motivation_2_rtt{sd_no}.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "#     sd1=['C','B']#0\n",
    "#     sd2=['S','V']#35\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "#    # data=FP_relay_num[0]\n",
    "\n",
    "    \n",
    "#     x=[]\n",
    "#     for item in data:\n",
    "#         for d in item:\n",
    "            \n",
    "#     ecdf = sm.distributions.ECDF(data[0])\n",
    "#     x = np.linspace(0, max(data[0]))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 3,ls='--',color='orange',label=f'{sd1[0]}-{sd1[1]} FP')\n",
    "# #     data=load_data('Egypt',0,144)[1]\n",
    "#    #data=FN_relay_num[0]\n",
    "#     print(max(data[0]),max(data[1]))\n",
    "#     ecdf = sm.distributions.ECDF(data[1])\n",
    "#     x = np.linspace(0, max(data[1]))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 3,ls='-.',color='orange',label=f'{sd1[0]}-{sd1[1]} FN')\n",
    "#     data=load_single_alibi_data('Egypt',35,144,600)\n",
    "#     #data=FP_relay_num2[0]\n",
    "#     for i in range(len(data[0])):\n",
    "#         data[0][i]=1-data[0][i]\n",
    "#     for i in range(len(data[1])):\n",
    "#         data[1][i]=1-data[1][i]\n",
    "#     ecdf = sm.distributions.ECDF(data[0])\n",
    "#     x = np.linspace(0, max(data[0]))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 1,ls='--',color='blue',label=f'{sd2[0]}-{sd2[1]} FP')\n",
    "\n",
    "# #     data=load_data('Egypt',35,144)[1]\n",
    "#     #data=FN_relay_num2[0]\n",
    "#     ecdf = sm.distributions.ECDF(data[1])\n",
    "#     x = np.linspace(0, max(data[1]))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 1,ls='-.',color='blue',label=f'{sd2[0]}-{sd2[1]} FN')\n",
    "#     print(max(data[0]),max(data[1]))\n",
    "#     plt.xlabel('Error ratios per 10min',size=18)\n",
    "\n",
    "# #     plt.xlabel('# of error relays per time window (600s)',size=18)\n",
    "#     plt.ylabel('CDF',size=18)\n",
    "#     _xtick_labels=[i/10 for i in range(0,11)]\n",
    "#     plt.xticks(_xtick_labels[::2])  \n",
    "#     ax.tick_params(axis='x', labelsize=16)\n",
    "#     ax.tick_params(axis='y', labelsize=16)\n",
    "#     plt.xlim(0,1)\n",
    "#     plt.ylim(0,1)\n",
    "#     plt.legend( loc='lower right', fontsize = 15)\n",
    "#    # plt.savefig(f'/home/chenwei/China_communications/code/code/data/path_verification/motivation/pictures/motivation_2_city_pairs_ratio.pdf', bbox_inches='tight')\n",
    "    \n",
    "# #     plt.savefig(f'/home/chenwei/China_communications/code/code/data/path_verification/motivation/pictures/motivation_relay_rate.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "'''moti two city pairs'''\n",
    "#     sd1=['C','B']#0\n",
    "#     sd2=['S','V']#35\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "#     sd_no=0\n",
    "#     file=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/0/{sd_no}_600.txt','r')\n",
    "#     data=eval(file.readline())\n",
    "    \n",
    "#     plt.rcParams['pdf.fonttype'] = 42 \n",
    "#     fp=[]\n",
    "#     fn=[]\n",
    "#     for items in data:\n",
    "#         fp_=0\n",
    "#         fn_=0\n",
    "#         for info in items:\n",
    "#             fp_+=info[3]\n",
    "#             fn_+=info[4]\n",
    "#         fp.append(fp_/600)\n",
    "#         fn.append(fn_/600)\n",
    "#     ecdf = sm.distributions.ECDF(fp)\n",
    "#     x = np.linspace(0, max(fp))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 3,ls='--',color='orange',label=f'{sd1[0]}-{sd1[1]} FP')\n",
    "# #     data=load_data('Egypt',0,144)[1]\n",
    "#    #data=FN_relay_num[0]\n",
    "#     print(max(fp),max(fn),np.mean(fp),np.mean(fn))\n",
    "#     ecdf = sm.distributions.ECDF(fn)\n",
    "#     x = np.linspace(0, max(fn))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 3,ls='-.',color='orange',label=f'{sd1[0]}-{sd1[1]} FN')\n",
    "#     sd_no=35\n",
    "#     file=open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/Egypt/0/{sd_no}_600.txt','r')\n",
    "#     data=eval(file.readline())\n",
    "#     fp=[]\n",
    "#     fn=[]\n",
    "#     for items in data:\n",
    "#         fp_=0\n",
    "#         fn_=0\n",
    "#         for info in items:\n",
    "#             fp_+=info[3]\n",
    "#             fn_+=info[4]\n",
    "#         fp.append(fp_/600)\n",
    "#         fn.append(fn_/600)\n",
    "#     ecdf = sm.distributions.ECDF(fp)\n",
    "#     x = np.linspace(0, max(fp))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 1,ls='--',color='blue',label=f'{sd2[0]}-{sd2[1]} FP')\n",
    "\n",
    "# #     data=load_data('Egypt',35,144)[1]\n",
    "#     #data=FN_relay_num2[0]\n",
    "#     ecdf = sm.distributions.ECDF(fn)\n",
    "#     x = np.linspace(0, max(fn))\n",
    "#     y = ecdf(x)\n",
    "#     plt.plot(x, y, linewidth = 1,ls='-.',color='blue',label=f'{sd2[0]}-{sd2[1]} FN')\n",
    "#     print(max(fp),max(fn),np.mean(fp),np.mean(fn))\n",
    "#     plt.xlabel('Error ratios per 10min',size=18)\n",
    "\n",
    "# #     plt.xlabel('# of error relays per time window (600s)',size=18)\n",
    "#     plt.ylabel('CDF',size=18)\n",
    "#     _xtick_labels=[i/10 for i in range(0,11)]\n",
    "#     plt.xticks(_xtick_labels[::2])  \n",
    "#     ax.tick_params(axis='x', labelsize=16)\n",
    "#     ax.tick_params(axis='y', labelsize=16)\n",
    "#     plt.xlim(0,1)\n",
    "#     plt.ylim(0,1)\n",
    "#     plt.legend( loc='lower right', fontsize = 15)\n",
    "#     plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/moti_6000s/fig/motivation_2_city_pairs_ratio.pdf', bbox_inches='tight')\n",
    "    \n",
    "# #     plt.savefig(f'/home/chenwei/China_communications/code/code/data/path_verification/motivation/pictures/motivation_relay_rate.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "ana_moti(600,86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part: Analyze evaluation———process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain data of FN/FP of Alibi in different time windows'''\n",
    "def get_data_alibi(risk_country):\n",
    "    alibi_300,alibi_600=[[],[]],[[],[]]\n",
    "    sca_alibi_300,sca_alibi_600=[[1000,0],[1000,0]],[[1000,0],[1000,0]]\n",
    "    for sd_no in range(198):\n",
    "        d0,d1=[[],[]],[[],[]]\n",
    "        try:\n",
    "            with open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/{risk_country}/data_process/{sd_no}_300.txt','r')as f:\n",
    "                data=eval(f.readline())\n",
    "                for info in data:\n",
    "                    d0[0].append(info[0]/300)\n",
    "                    d0[1].append(info[1]/300)\n",
    "                    sca_alibi_300[0][0]=min(sca_alibi_300[0][0],info[0]/300)\n",
    "                    sca_alibi_300[0][1]=max(sca_alibi_300[0][1],info[0]/300)\n",
    "                    sca_alibi_300[1][0]=min(sca_alibi_300[1][0],info[1]/300)\n",
    "                    sca_alibi_300[1][1]=max(sca_alibi_300[1][1],info[1]/300)\n",
    "                alibi_300[0].append(np.mean(d0[0]))\n",
    "                alibi_300[1].append(np.mean(d0[1]))\n",
    "        except:pass\n",
    "        try:\n",
    "            with open(f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/{risk_country}/data_process/{sd_no}_600.txt','r')as f:\n",
    "                data=eval(f.readline())\n",
    "                for info in data:\n",
    "                    d1[0].append(info[0]/600)\n",
    "                    d1[1].append(info[1]/600)\n",
    "                    sca_alibi_600[0][0]=min(sca_alibi_600[0][0],info[0]/600)\n",
    "                    sca_alibi_600[0][1]=max(sca_alibi_600[0][1],info[0]/600)\n",
    "                    sca_alibi_600[1][0]=min(sca_alibi_600[1][0],info[1]/600)\n",
    "                    sca_alibi_600[1][1]=max(sca_alibi_600[1][1],info[1]/600)\n",
    "                alibi_600[0].append(np.mean(d1[0]))\n",
    "                alibi_600[1].append(np.mean(d1[1]))\n",
    "        except:pass\n",
    "    return alibi_300,alibi_600,sca_alibi_300,sca_alibi_600\n",
    "alibi_300_E,alibi_600_E,sca_alibi_300_E,sca_alibi_600_E=get_data_alibi('Egypt')\n",
    "alibi_300_K,alibi_600_K,sca_alibi_300_K,sca_alibi_600_K=get_data_alibi('Korea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain delay inflation of Alibi'''\n",
    "def get_alibi_delay_inflation(risk_country,factor):\n",
    "    def baseline(sd_no):\n",
    "        min_delay=[]\n",
    "        try:\n",
    "            csv_reader=csv.reader(open(f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/verify_results/{risk_country}_Starlink1/{sd_no}.csv'))\n",
    "            for line in csv_reader:\n",
    "                try:\n",
    "                    min_delay.append(eval(line[0]))\n",
    "                except:\n",
    "                    min_delay.append(-1)\n",
    "        except:pass\n",
    "        return min_delay\n",
    "    delays=[]\n",
    "    gs=[]\n",
    "    with open(f'/data/chenwei/research3/data/sd_shortest_gs/{risk_country}/shortest_gs_{factor}.txt','r')as f:\n",
    "        gs=eval(f.readline())\n",
    "       \n",
    "    for sd_no in tqdm(range(198)):\n",
    "        delay=[]\n",
    "        if gs[sd_no]==-1:continue\n",
    "        min_delay=baseline(sd_no)\n",
    "        if min_delay==[]:continue\n",
    "        try:\n",
    "            filepath=f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/{risk_country}/{factor}/{sd_no}_600.txt'\n",
    "            if not os.path.exists(filepath):\n",
    "                filepath=f'/data/chenwei/research3/data/StarVeri_ICNP/alibi/24h/{risk_country}/0/{sd_no}_600.txt'\n",
    "            with open(filepath,'r')as f:\n",
    "                lines=eval(f.readline())\n",
    "                _=0\n",
    "                for infos in lines[:10]:\n",
    "                    base=infos[0][1]\n",
    "                    count=0\n",
    "                    for t in range(_*600,infos[0][0]):\n",
    "                        if base==-1 and min_delay[t]!=-1:delay.append((0.2-min_delay[t])/min_delay[t]*100)\n",
    "                        elif base==-1 and min_delay[t]==-1:continue\n",
    "                        elif base!=-1 and min_delay[t]==-1:continue\n",
    "                        else:\n",
    "                            delay.append((base-min_delay[t])/base*100)\n",
    "                    t=infos[0][0]\n",
    "                    for info in infos:\n",
    "                        if info[2]==-1 and min_delay[t]!=-1:\n",
    "                            delay.append((0.2-min_delay[t])/min_delay[t]*100)\n",
    "                        elif info[2]==-1 and min_delay[t]==-1:continue\n",
    "                        elif info[2]!=-1 and min_delay[t]==-1:continue\n",
    "                        else:\n",
    "                            delay.append((info[2]-min_delay[t])/min_delay[t]*100)\n",
    "                        t+=1\n",
    "                    _+=1\n",
    "        except:continue\n",
    "        delays.append(np.mean(delay))\n",
    "    return delays\n",
    "di_E_alibi_0=get_alibi_delay_inflation('Egypt',0)\n",
    "di_E_alibi_05=get_alibi_delay_inflation('Egypt',0.5)\n",
    "di_K_alibi_05=get_alibi_delay_inflation('Korea',0.5)\n",
    "di_K_alibi_0=get_alibi_delay_inflation('Korea',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain FP/FN of StarVeri in different time windows'''\n",
    "import csv\n",
    "def get_data_starveri_result(risk_country,constellation):\n",
    "    alibi_300,alibi_600=[[[],[]],[[],[]],[[],[]]],[[[],[]],[[],[]],[[],[]]]\n",
    "    sca_alibi_300,sca_alibi_600=[[[1000,0],[1000,0]],[[1000,0],[1000,0]],[[1000,0],[1000,0]]],[[[1000,0],[1000,0]],[[1000,0],[1000,0]],[[1000,0],[1000,0]]]\n",
    "    for sd_no in range(198):\n",
    "        \n",
    "        try:\n",
    "            csv_reader = csv.reader(open(f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/verify_results/results/{risk_country}_{constellation}/{sd_no}.csv'))\n",
    "            ind,step,_=0,300,0\n",
    "            d3,d4=[[0,0],[0,0],[0,0]],[[0,0],[0,0],[0,0]]\n",
    "            d0,d1=[[[],[]],[[],[]],[[],[]]],[[[],[]],[[],[]],[[],[]]]\n",
    "            for line in csv_reader:\n",
    "                if ind>=_*600 and ind<_*600+300:\n",
    "                    if eval(line[0])==1:d3[0][0]+=1\n",
    "                    else :d3[0][1]+=1\n",
    "                    if eval(line[1])==1:d3[1][0]+=1\n",
    "                    else :d3[1][1]+=1\n",
    "                    if eval(line[2])==1:d3[2][0]+=1\n",
    "                    else :d3[2][1]+=1\n",
    "                if ind>=_*600 and ind<_*600+600:\n",
    "                    if eval(line[0])==1:d4[0][0]+=1\n",
    "                    else :d4[0][1]+=1\n",
    "                    if eval(line[1])==1:d4[1][0]+=1\n",
    "                    else :d4[1][1]+=1\n",
    "                    if eval(line[2])==1:d4[2][0]+=1\n",
    "                    else :d4[2][1]+=1\n",
    "                if ind==_*600+600:\n",
    "                    d0[0][0].append(d3[0][0]/300)\n",
    "                    d0[0][1].append(d3[0][1]/300)\n",
    "                    d0[1][0].append(d3[1][0]/300)\n",
    "                    d0[1][1].append(d3[1][1]/300)\n",
    "                    d0[2][0].append(d3[2][0]/300)\n",
    "                    d0[2][1].append(d3[2][1]/300)\n",
    "                    d1[0][0].append(d4[0][0]/600)\n",
    "                    d1[0][1].append(d4[0][1]/600)\n",
    "                    d1[1][0].append(d4[1][0]/600)\n",
    "                    d1[1][1].append(d4[1][1]/600)\n",
    "                    d1[2][0].append(d4[2][0]/600)\n",
    "                    d1[2][1].append(d4[2][1]/600)\n",
    "                    \n",
    "                    sca_alibi_300[0][0][0]=min(sca_alibi_300[0][0][0],d3[0][0]/300)\n",
    "                    sca_alibi_300[0][0][1]=max(sca_alibi_300[0][0][1],d3[0][0]/300)\n",
    "                    sca_alibi_300[0][1][0]=min(sca_alibi_300[0][1][0],d3[0][1]/300)\n",
    "                    sca_alibi_300[0][1][1]=max(sca_alibi_300[0][1][1],d3[0][1]/300)\n",
    "\n",
    "                    sca_alibi_300[1][0][0]=min(sca_alibi_300[1][0][0],d3[1][0]/300)\n",
    "                    sca_alibi_300[1][0][1]=max(sca_alibi_300[1][0][1],d3[1][0]/300)\n",
    "                    sca_alibi_300[1][1][0]=min(sca_alibi_300[1][1][0],d3[1][1]/300)\n",
    "                    sca_alibi_300[1][1][1]=max(sca_alibi_300[1][1][1],d3[1][1]/300)\n",
    "\n",
    "                    sca_alibi_300[2][0][0]=min(sca_alibi_300[2][0][0],d3[2][0]/300)\n",
    "                    sca_alibi_300[2][0][1]=max(sca_alibi_300[2][0][1],d3[2][0]/300)\n",
    "                    sca_alibi_300[2][1][0]=min(sca_alibi_300[2][1][0],d3[2][1]/300)\n",
    "                    sca_alibi_300[2][1][1]=max(sca_alibi_300[2][1][1],d3[2][1]/300)\n",
    "\n",
    "                    sca_alibi_600[0][0][0]=min(sca_alibi_600[0][0][0],d4[0][0]/600)\n",
    "                    sca_alibi_600[0][0][1]=max(sca_alibi_600[0][0][1],d4[0][0]/600)\n",
    "                    sca_alibi_600[0][1][0]=min(sca_alibi_600[0][1][0],d4[0][1]/600)\n",
    "                    sca_alibi_600[0][1][1]=max(sca_alibi_600[0][1][1],d4[0][1]/600)\n",
    "\n",
    "                    sca_alibi_600[1][0][0]=min(sca_alibi_600[1][0][0],d4[1][0]/600)\n",
    "                    sca_alibi_600[1][0][1]=max(sca_alibi_600[1][0][1],d4[1][0]/600)\n",
    "                    sca_alibi_600[1][1][0]=min(sca_alibi_600[1][1][0],d4[1][1]/600)\n",
    "                    sca_alibi_600[1][1][1]=max(sca_alibi_600[1][1][1],d4[1][1]/600)\n",
    "\n",
    "                    sca_alibi_600[2][0][0]=min(sca_alibi_600[2][0][0],d4[2][0]/600)\n",
    "                    sca_alibi_600[2][0][1]=max(sca_alibi_600[2][0][1],d4[2][0]/600)\n",
    "                    sca_alibi_600[2][1][0]=min(sca_alibi_600[2][1][0],d4[2][1]/600)\n",
    "                    sca_alibi_600[2][1][1]=max(sca_alibi_600[2][1][1],d4[2][1]/600)\n",
    "                    d3,d4=[[0,0],[0,0],[0,0]],[[0,0],[0,0],[0,0]]\n",
    "                    _+=1\n",
    "                ind+=1\n",
    "            alibi_300[0][0].append(np.mean(d0[0][0]))\n",
    "            alibi_300[0][1].append(np.mean(d0[0][1]))\n",
    "            alibi_300[1][0].append(np.mean(d0[1][0]))\n",
    "            alibi_300[1][1].append(np.mean(d0[1][1]))\n",
    "            alibi_300[2][0].append(np.mean(d0[2][0]))\n",
    "            alibi_300[2][1].append(np.mean(d0[2][1]))\n",
    "            \n",
    "            alibi_600[0][0].append(np.mean(d1[0][0]))\n",
    "            alibi_600[0][1].append(np.mean(d1[0][1]))\n",
    "            alibi_600[1][0].append(np.mean(d1[1][0]))\n",
    "            alibi_600[1][1].append(np.mean(d1[1][1]))\n",
    "            alibi_600[2][0].append(np.mean(d1[2][0]))\n",
    "            alibi_600[2][1].append(np.mean(d1[2][1]))\n",
    "        except:pass\n",
    "    return alibi_300,alibi_600,sca_alibi_300,sca_alibi_600\n",
    "star_300_E_st,star_600_E_st,sca_star_300_E_st,sca_star_600_E_st=get_data_starveri_result('Egypt','Starlink1')\n",
    "star_300_K_st,star_600_K_st,sca_star_300_K_st,sca_star_600_K_st=get_data_starveri_result('Korea','Starlink1')\n",
    "star_300_E_kp,star_600_E_kp,sca_star_300_E_kp,sca_star_600_E_kp=get_data_starveri_result('Egypt','Kuiper1')\n",
    "star_300_K_kp,star_600_K_kp,sca_star_300_K_kp,sca_star_600_K_kp=get_data_starveri_result('Korea','Kuiper1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtatin data of NLRP: variation time/frequency'''\n",
    "def get_nlrp_frequency(risk_country,constellation):\n",
    "    fre1,fre2=[],[]\n",
    "    rsf0,rsf1=[],[]\n",
    "    pre0,pre1,prers0,prers1=[],[],[],[]\n",
    "    for t in range(6000):\n",
    "        try:\n",
    "            if constellation=='Starlink1':\n",
    "                file=f'/data/chenwei/research3/data/NLRP_24h/{risk_country}/{t}.txt'\n",
    "            else:\n",
    "                file=f'/data/chenwei/research3/data/NLRP_24h/Kuiper1/{risk_country}/{t}.txt'\n",
    "            f=open(file,'r')\n",
    "            lines=f.readlines()\n",
    "            nlrp=eval(lines[0])\n",
    "            rsats=eval(lines[1])\n",
    "            \n",
    "            if rsats[0]!=prers0:\n",
    "                rsf0.append(t)\n",
    "                prers0=rsats[0]\n",
    "            if rsats[1]!=prers1:\n",
    "                rsf1.append(t)\n",
    "                prers1=rsats[1]\n",
    "            if nlrp[0]!=pre0:\n",
    "                pre0=nlrp[0]\n",
    "                fre1.append(t)\n",
    "            if nlrp[1]!=pre1:\n",
    "                pre1=nlrp[1]\n",
    "                fre2.append(t)\n",
    "            f.close()\n",
    "        except:\n",
    "            continue\n",
    "    return fre1,fre2,rsf0,rsf1\n",
    "nlrp0_st,nlrp1_st,rs0_st,rs1_st=get_nlrp_frequency('Egypt','Starlink1')\n",
    "nlrp0_kp,nlrp1_kp,rs0_kp,rs1_kp=get_nlrp_frequency('Egypt','Kuiper1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain RAR of Starveri'''\n",
    "def get_rar(risk_country,constellation):\n",
    "    theta0,theta1=[[],[],[]],[[],[],[]]\n",
    "    for sd_no in tqdm(range(198)):\n",
    "        t0,t1=[0,0,0],[0,0,0]\n",
    "        c=0\n",
    "        try:\n",
    "            filepath=f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/verify_results/{risk_country}_{constellation}/{sd_no}.csv'\n",
    "            csv_reader = csv.reader(open(filepath))\n",
    "            for line in csv_reader:\n",
    "                if line==['-1'] or line==[]:continue\n",
    "                data=[eval(line[1]),eval(line[2])]\n",
    "                if data[0][2][0]==[]:t0[0]+=1\n",
    "                else:t0[len(data[0][0])-2]+=1\n",
    "                if data[1][2][0]==[]:t1[0]+=1\n",
    "                else:t1[len(data[1][0])-2]+=1\n",
    "                c+=1\n",
    "            theta0[0].append(t0[0]/c)\n",
    "            theta0[1].append(t0[1]/c)  \n",
    "            theta0[2].append(t0[2]/c)  \n",
    "            theta1[0].append(t1[0]/c)\n",
    "            theta1[1].append(t1[1]/c)  \n",
    "            theta1[2].append(t1[2]/c)  \n",
    "        except:continue\n",
    "    return theta0,theta1\n",
    "theta0_st_E,theta1_st_E=get_rar(risk_country='Egypt',constellation='Starlink1')\n",
    "theta0_kp_E,theta1_kp_E=get_rar(risk_country='Egypt',constellation='Kuiper1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain delay info etc. of Starveri'''\n",
    "def get_star_data_delay(risk_country,constellation):\n",
    "    data0,data1,data2=[],[],[]\n",
    "    t0,t1,t2=[],[],[]\n",
    "    for sd_no in tqdm(range(198)):\n",
    "        filepath=f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/verify_results/{risk_country}_{constellation}/{sd_no}.csv'\n",
    "        if os.path.exists(filepath):\n",
    "            csv_reader = csv.reader(open(filepath))\n",
    "            d0,d1,d2=[],[],[]\n",
    "        for line in csv_reader:\n",
    "            if line=='-1':continue\n",
    "            try:\n",
    "                min_delay=eval(line[0])\n",
    "                data=[eval(line[1]),eval(line[2]),eval(line[3])]\n",
    "                if data[0][2][0]==[]:d0.append(0)\n",
    "                else:\n",
    "                    d0.append((data[0][1]-min_delay)/min_delay*100)\n",
    "                    for info in data[0][2]:\n",
    "                        t0.append(info[1]*1e3)\n",
    "                if data[1][2][0]==[]:d1.append(0)\n",
    "                else:\n",
    "                    d1.append((data[1][1]-min_delay)/min_delay*100)\n",
    "                    for info in data[1][2]:\n",
    "                        t1.append(info[1]*1e3)\n",
    "                if data[2][2][0]==[]:d2.append(0)\n",
    "                else:\n",
    "                    d2.append((data[2][1]-min_delay)/min_delay*100)\n",
    "                    for info in data[2][2]:\n",
    "                        t2.append(info[1]*1e3)\n",
    "            except:continue\n",
    "        data0.append(np.mean(d0))\n",
    "        data1.append(np.mean(d1))\n",
    "        data2.append(np.mean(d2))\n",
    "    return data0,data1,data2,t0,t1,t2\n",
    "# delay_E_st_0,delay_E_st_1,delay_E_st_2,thr_E_st_0,thr_E_st_1,thr_E_st_2=get_star_data_delay('Egypt','Starlink1')\n",
    "# delay_K_st_0,delay_K_st_1,delay_K_st_2,thr_K_st_0,thr_K_st_1,thr_K_st_2=get_star_data_delay('Korea','Starlink1')\n",
    "# delay_E_kp_0,delay_E_kp_1,delay_E_kp_2,thr_E_kp_0,thr_E_kp_1,thr_E_kp_2=get_star_data_delay('Egypt','Kuiper1')\n",
    "# delay_K_kp_0,delay_K_kp_1,delay_K_kp_2,thr_K_kp_0,thr_K_kp_1,thr_K_kp_2=get_star_data_delay('Korea','Kuiper1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain delay info of StarryNet'''\n",
    "def get_emu_result():\n",
    "    process_delay=[]\n",
    "    min_max=[[0,10000],[0,10000],[0,10000]]\n",
    "    sd=[55,74,0]\n",
    "    min_delay=[0.236731/2,0.256720/2,0.246980/2]\n",
    "    for ind,sd_no in enumerate(sd):\n",
    "        send,rev=[],[]\n",
    "        delay=[]\n",
    "        with open(f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/starrynet/72_22/ts_{sd_no}_rev.txt','r')as f:\n",
    "            lines=f.readlines()\n",
    "            for line in lines:\n",
    "                rev.append(eval(line))\n",
    "        with open(f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/starrynet/72_22/ts_{sd_no}_send.txt','r')as f:\n",
    "            lines=f.readlines()\n",
    "            for line in lines:\n",
    "                send.append(eval(line))\n",
    "        for i in range(min(len(send),len(rev))):\n",
    "            d=(rev[i]-send[i]-min_delay[ind])*1e6-19.3119\n",
    "            if d<0:continue\n",
    "            delay.append(d)\n",
    "            min_max[ind][0]=max(min_max[ind][0],d)\n",
    "            min_max[ind][1]=min(min_max[ind][1],d)\n",
    "        process_delay.append(np.mean(delay))\n",
    "    return process_delay,min_max\n",
    "process_delay_emu,min_max_process_delay_emu=get_emu_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''process the relations of NLRP size and delay of Starveri'''\n",
    "def get_star_balance(risk_country,constellation):\n",
    "    d0,d1,d2=[],[],[]\n",
    "    t0,t1,t2=[],[],[]\n",
    "    for sd_no in tqdm(range(1,2)):\n",
    "        d00,d11,d22=[],[],[]\n",
    "        t00,t11,t22=[],[],[]\n",
    "        try:\n",
    "            csv_reader=csv.reader(open(f'/data/chenwei/research3/data/StarVeri_ICNP/starveri/verify_results/{risk_country}_{constellation}/{sd_no}.csv'))\n",
    "            for line in csv_reader:\n",
    "                if line==['-1']:continue\n",
    "                min_delay=eval(line[0])\n",
    "                data=[eval(line[1]),eval(line[2]),eval(line[3])]\n",
    "                if data[0][2][0]==[]:continue\n",
    "                if data[0][1]>=data[1][1]:continue\n",
    "                d0.append((data[0][1]-min_delay)/min_delay*100)\n",
    "                m=1000\n",
    "                for info in data[0][2]:\n",
    "                    m=min(m,info[1]*1e3)\n",
    "                t0.append(m)\n",
    "                \n",
    "                m=1000\n",
    "                for info in data[1][2]:\n",
    "                    m=min(m,info[1]*1e3)\n",
    "                t1.append(m)\n",
    "                d1.append((data[1][1]-min_delay)/min_delay*100)\n",
    "                m=1000\n",
    "                for info in data[2][2]:\n",
    "                    m=min(m,info[1]*1e3)\n",
    "                t2.append(m)\n",
    "                d2.append((data[2][1]-min_delay)/min_delay*100)\n",
    "            \n",
    "#             t0.append(np.mean(t00))\n",
    "#             t1.append(np.mean(t11))\n",
    "#             t2.append(np.mean(t22))\n",
    "#             d0.append(np.mean(d00))\n",
    "#             d1.append(np.mean(d11))\n",
    "#             d2.append(np.mean(d22))\n",
    "        except:continue\n",
    "    return d0,d1,d2,t0,t1,t2\n",
    "re_st_E_delay0,re_st_E_delay1,re_st_E_delay2,re_st_E_tr0,re_st_E_tr1,re_st_E_tr2=get_star_balance(risk_country='Egypt',constellation='Starlink1')\n",
    "re_kp_E_delay0,re_kp_E_delay1,re_kp_E_delay2,re_kp_E_tr0,re_kp_E_tr1,re_kp_E_tr2=get_star_balance(risk_country='Egypt',constellation='Kuiper1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "def eva(risk_country,constellation,FP):\n",
    "    import matplotlib as mpl\n",
    "    from matplotlib import cm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    import InterestingColorfulColor as ICC\n",
    "    import json\n",
    "    import random\n",
    "    import csv\n",
    "    import copy\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    plt.rcParams['pdf.fonttype'] = 42\n",
    "    '''draw security and threshold balance'''\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "    \n",
    "#     if constellation=='Starlink1':\n",
    "# #         d1,d2,d3=[],[],[]\n",
    "# #         r1,r2,r3=[],[],[]\n",
    "# #         for i in range(len(re_st_E_delay0)):\n",
    "# #             al=re_st_E_tr0[i]+re_st_E_tr1[i]+re_st_E_tr2[i]\n",
    "# #             r1.append(re_st_E_tr0[i]/al)\n",
    "# #             r2.append(re_st_E_tr1[i]/al)\n",
    "# #             r3.append(re_st_E_tr2[i]/al)\n",
    "# # #             r3.append((re_kp_E_tr2[i]-mi)/(ax-mi))\n",
    "# #             al=re_st_E_delay0[i]+re_st_E_delay1[i]+re_st_E_delay2[i]\n",
    "# # #             ax=max(re_kp_E_delay0[i],max(re_kp_E_delay1[i],re_kp_E_delay2[i]))\n",
    "# # #             mi=min(re_kp_E_delay0[i],min(re_kp_E_delay1[i],re_kp_E_delay2[i]))\n",
    "# #             d1.append(re_st_E_delay0[i]/al)\n",
    "# #             d2.append(re_st_E_delay1[i]/al)\n",
    "# #             d3.append(re_st_E_delay2[i]/al)\n",
    "            \n",
    "#         data0=[re_st_E_delay0,re_st_E_delay1,re_st_E_delay2]\n",
    "#         data1=[re_st_E_tr0,re_st_E_tr1,re_st_E_tr2]\n",
    "#     else:\n",
    "# #         d1,d2,d3=[],[],[]\n",
    "# #         r1,r2,r3=[],[],[]\n",
    "# #         for i in range(len(re_kp_E_delay0)):\n",
    "# # #             ax=max(re_kp_E_tr0[i],max(re_kp_E_tr1[i],re_kp_E_tr2[i]))\n",
    "# # #             mi=min(re_kp_E_tr0[i],min(re_kp_E_tr1[i],re_kp_E_tr2[i]))\n",
    "# # #             if ax==mi:continue\n",
    "# #             al=re_kp_E_tr0[i]+re_kp_E_tr1[i]+re_kp_E_tr2[i]\n",
    "# #             r1.append(re_kp_E_tr0[i]/al)\n",
    "# #             r2.append(re_kp_E_tr1[i]/al)\n",
    "# #             r3.append(re_kp_E_tr2[i]/al)\n",
    "# # #             r3.append((re_kp_E_tr2[i]-mi)/(ax-mi))\n",
    "# #             al=re_kp_E_delay0[i]+re_kp_E_delay1[i]+re_kp_E_delay2[i]\n",
    "# # #             ax=max(re_kp_E_delay0[i],max(re_kp_E_delay1[i],re_kp_E_delay2[i]))\n",
    "# # #             mi=min(re_kp_E_delay0[i],min(re_kp_E_delay1[i],re_kp_E_delay2[i]))\n",
    "# #             d1.append(re_kp_E_delay0[i]/al)\n",
    "# #             d2.append(re_kp_E_delay1[i]/al)\n",
    "# #             d3.append(re_kp_E_delay2[i]/al)\n",
    "# # #             d2.append((re_kp_E_delay1[i]-mi)/(ax-mi))\n",
    "# # #             d3.append((re_kp_E_delay1[i]-mi)/(ax-mi))\n",
    "            \n",
    "#         data0=[re_kp_E_delay0,re_kp_E_delay1,re_kp_E_delay2]\n",
    "#         data1=[re_kp_E_tr0,re_kp_E_tr1,re_kp_E_tr2]\n",
    "#     colors=['darkred','lightblue','orange']\n",
    "#     label=[r'$\\theta$=1',r'$\\theta$=2',r'$\\theta$=3']\n",
    "#     for i in range(len(data0)):\n",
    "#         plt.scatter(data0[i],data1[i],marker='.', s=5, color=colors[i],label=label[i]) \n",
    "#     ax.set_ylabel('Detour thresholds(ms)',size=18)\n",
    "#     ax.set_xlabel('Delay inflation(%)',size=18)\n",
    "#     ax.legend(loc='upper right',fontsize=12)\n",
    "#     plt.show()\n",
    "    '''draw emu process delay'''\n",
    "#     paths=[[614, 636, 658, 680, 702, 724, 746, 768, 790, 812, 834, 856, 878, 900, 922, 944, 966, 988, 1010, 1032, 1054, 1076, 1098, 1120, 1142, 1164, 1186, 1208, 1230, 1252, 1274, 1296, 1318, 1340, 1362, 1384],\n",
    "#           [679, 680, 681, 703, 725, 747, 769, 791, 813, 835, 857, 879, 901, 923, 945, 967, 989, 1011, 1033, 1055, 1077, 1099, 1121, 1143, 1165, 1187, 1209, 1231, 1253, 1275, 1297, 1319, 1341],\\\n",
    "#           [1525, 1526, 1548, 1570, 8, 30, 52, 74, 96, 118, 140, 162, 184, 206, 228, 250, 272, 294, 316, 338, 360, 382, 404, 426, 448, 470, 492, 514, 536, 558, 580, 602, 624, 646, 645],]\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "#     min_delay=[0.236731/2,0.256720/2,0.246980/2]\n",
    "#     hbh_data=[0,0,0]\n",
    "#     for i in range(3):\n",
    "#         hbh_data[i]=len(paths[i])*211.621/2+min_delay[i]*1e6\n",
    "#         print(len(paths[i]),end=' ')\n",
    "#     custom_x = np.arange(3) * 2\n",
    "#     name = [r'$\\sigma$=0',r'$\\sigma$=1', r'$\\sigma$=2']\n",
    "#     hatch_par = ['/', '', '|', '-', '+', 'x', 'o', 'O', '.', '*']\n",
    "#     bar_width = 0.8#total_width / n\n",
    "#     data1_middles = custom_x\n",
    "#     data2_middles = custom_x + bar_width/2\n",
    "#     print(process_delay_emu,hbh_data,min_max_process_delay_emu)\n",
    "#     rects1 = ax.bar(custom_x, process_delay_emu, bar_width,label='STARVERI',hatch=hatch_par[0], color='lightblue')\n",
    "#     #rects2 = ax.bar(custom_x+ bar_width/2, hbh_data, bar_width,label='hop-by-hop',hatch=hatch_par[1], color='orange')\n",
    "\n",
    "#     ind=1\n",
    "# #     for ind in range(len(name)):\n",
    "# #         ax.plot([data1_middles[ind], data1_middles[ind]], min_max_process_delay_emu[ind],marker='_', color='black')\n",
    "\n",
    "#     ax.set_ylabel(r'Process delay($\\mu$s)',size=18)\n",
    "#     #ax.set_title('Values by custom group positions')\n",
    "#     ax.set_xticks(custom_x)\n",
    "#     ax.set_xticklabels([i for i in name],size=12)\n",
    "#     #ax.legend(frameon = False,fontsize=11,bbox_to_anchor=(1, 0.99), loc='lower right', ncol=2, borderaxespad=0.05, handletextpad = 0.2, columnspacing = 0.4, labelspacing=0.2)\n",
    "\n",
    "# #     plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/emu_process_delay.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    '''draw RAR'''\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "#     name=[r'$\\sigma$'+\"=0,\"+r'$\\theta$'+\"=1\",r'$\\sigma$'+\"=0,\"+r'$\\theta$'+\"=2\",r'$\\sigma$'+\"=1,\"+r'$\\theta$'+\"=1\",r'$\\sigma$'+\"=1,\"+r'$\\theta$'+\"=2\",r'$\\sigma$'+\"=2,\"+r'$\\theta$'+\"=1\",r'$\\sigma$'+\"=2,\"+r'$\\theta$'+\"=2\"]\n",
    "#     data=[]\n",
    "#     if constellation=='Starlink1':\n",
    "#         data=[theta0_st_E[0],theta1_st_E[0],theta0_st_E[1],theta1_st_E[1],theta0_st_E[2],theta1_st_E[2]]\n",
    "#     else:\n",
    "#         data=[theta0_kp_E[0],theta1_kp_E[0],theta0_kp_E[1],theta1_kp_E[1],theta0_kp_E[2],theta1_kp_E[2]]\n",
    "\n",
    "#     ax.boxplot(data,showfliers=False)\n",
    "#     ax.set_xticklabels(name,rotation=45,size=12)     # set x label\n",
    "#     ax.set_ylabel('RAR(%)',size=15)\n",
    "# #     plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/{constellation}_rar.pdf', bbox_inches='tight')\n",
    "#     for i in data:\n",
    "#         print(np.mean(i),len(i),end=' ')\n",
    "#     plt.show()\n",
    "    '''Draw variation frequency'''\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "#     data=[]\n",
    "#     if constellation=='Starlink1':\n",
    "#         data0=[rs0_st,rs1_st,nlrp0_st,nlrp1_st]\n",
    "#         for info in data0:\n",
    "#             _=0\n",
    "#             count=[0 for _ in range(6)]\n",
    "#             for t in info:\n",
    "#                 if t>=_*1000 and t<_*1000+1000:\n",
    "#                     count[_]+=1\n",
    "#                 else:\n",
    "#                     _+=1\n",
    "#             data.append(count)\n",
    "#     else:\n",
    "#         data0=[rs0_kp,rs1_kp,nlrp0_kp,nlrp1_kp]\n",
    "#         for info in data0:\n",
    "#             _=0\n",
    "#             count=[0 for _ in range(6)]\n",
    "#             for t in info:\n",
    "#                 if t>=_*1000 and t<_*1000+1000:\n",
    "#                     count[_]+=1\n",
    "#                 else:\n",
    "#                     _+=1\n",
    "#             data.append(count)\n",
    "#     name=['RS N','RS S','NLRP N','NLRP S']\n",
    "#     x=[1000,2000,3000,4000,5000,6000]\n",
    "#     ls=['-','-.','--',':']\n",
    "#     for i in range(len(data)):\n",
    "#         plt.plot(x,data[i],linewidth=1.5,linestyle=ls[i],label=name[i],marker='o',markersize=4)\n",
    "#     plt.xlabel('Time(s)',size=18)\n",
    "#     plt.ylabel('Fre. of variation',size=18)\n",
    "#     #ax.set_yticklabels(name,size=12)    \n",
    "#     plt.xlim(999,6001)\n",
    "#     plt.ylim(0,50)\n",
    "#     ax.tick_params(axis='x', labelsize=16)\n",
    "#     ax.tick_params(axis='y', labelsize=16)\n",
    "#     ax.set_xticks(x)\n",
    "#     ax.legend(loc='lower right',fontsize=12)\n",
    "#     plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/{risk_country}_{constellation}_fre.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    '''draw delay threshold'''\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "#     data=[]\n",
    "#     if constellation=='Starlink1':\n",
    "#         data=[]\n",
    "# #     if constellation=='Starlink1' and risk_country=='Egypt':\n",
    "# #         data=[thr_E_st_0,thr_E_st_1,thr_E_st_2]\n",
    "# #     elif constellation=='Starlink1' and risk_country=='Korea':\n",
    "# #         data=[thr_K_st_0,thr_K_st_1,thr_K_st_2]\n",
    "# #     elif constellation=='Kuiper1' and risk_country=='Korea':\n",
    "# #         data=[thr_K_kp_0,thr_K_kp_1,thr_K_kp_2]\n",
    "# #     else:\n",
    "# #         data=[thr_E_kp_0,thr_E_kp_1,thr_E_kp_2]\n",
    "#     ax.boxplot(data,showfliers=False)\n",
    "#     ax.set_xticklabels([r'$\\theta=1$', r'$\\theta=2$', r'$\\theta=3$'],size=12)     # 设置x轴刻度标签\n",
    "#     ax.set_ylabel('Delay threshold(ms)',size=15)\n",
    "#    # plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/{risk_country}_{constellation}_dt.pdf', bbox_inches='tight')\n",
    "\n",
    "#     plt.show()\n",
    "    '''draw delay inflation'''\n",
    "    fig , ax = plt.subplots(figsize=(4, 3))\n",
    "    delay=[[]for i in range(6)]\n",
    "    delay0,delay1,delay2,delay3,delay4,delay5=[],[],[],[],[],[]\n",
    "    if constellation=='Starlink1' and risk_country=='Egypt':\n",
    "        delay=[delay_E_st_0,di_E_alibi_0,delay_E_st_1,di_E_alibi_05,delay_E_st_2]\n",
    "#         delay0,delay1,delay2,delay3,delay4,delay5=delay_E_st_0,delay_E_st_1,delay_E_st_2,delay_K_st_0,delay_K_st_1,delay_K_st_2\n",
    "    elif constellation =='Starlink1' and risk_country=='Korea':\n",
    "        delay=[delay_K_st_0,di_K_alibi_0,delay_K_st_1,di_K_alibi_05,delay_K_st_2]\n",
    "    elif constellation=='Kuiper1' and risk_country=='Egypt':\n",
    "        delay=[delay_E_kp_0,delay_E_kp_1,delay_E_kp_2]#,delay_K_kp_0,delay_K_kp_1,delay_K_kp_2]\n",
    "#         delay0,delay1,delay2,delay3,delay4,delay5=delay_E_kp_0,delay_E_kp_1,delay_E_kp_2,delay_K_kp_0,delay_K_kp_1,delay_K_kp_2\n",
    "    else:\n",
    "        delay=[delay_K_kp_0,delay_K_kp_1,delay_K_kp_2]\n",
    "    theta=['1','2','3','1','2','3']\n",
    "    ls=['-','-.','--','-','-.','--']\n",
    "    linewidth=1\n",
    "    linec=['darkred','blue','darkred','blue','darkred']\n",
    "    marker=['','^','','o','','o']\n",
    "    name=[r'STAR,$\\theta$=1','Alibi,f=0',r'STAR,$\\theta$=2','Alibi,f=0.5',r'STAR,$\\theta$=3']\n",
    "    ra=[]\n",
    "    for ind in range(len(delay)):\n",
    "        data=delay[ind]\n",
    "        ecdf = sm.distributions.ECDF(data)\n",
    "        x = np.linspace(0, max(data))\n",
    "        y = ecdf(x)\n",
    "#         plt.plot(x, y, linewidth = linewidth,ls=ls[ind],color=linec,label=r'$\\theta$='+theta[ind])\n",
    "        plt.plot(x, y, linewidth = linewidth,ls=ls[ind],color=linec[ind],marker=marker[ind],ms=3,label=name[ind])\n",
    "#         if ind<3:\n",
    "#         plt.plot(x, y, linewidth = linewidth,ms=5,ls=ls[ind],color=linec,marker=marker[0],markerfacecolor='darkred',label=)\n",
    "#         else:\n",
    "#             plt.plot(x, y, linewidth = linewidth,ms=5,ls=ls[ind],color=linec,marker=marker[1],markerfacecolor='b')\n",
    "    custom_lines = [\n",
    "        mlines.Line2D([], [], color=linec[0], marker=marker[0],linestyle=ls[0], linewidth = linewidth,label=name[0]),\n",
    "        mlines.Line2D([], [], linestyle='None', label=''),\n",
    "        mlines.Line2D([], [], color=linec[2], linestyle=ls[2],  marker=marker[2],linewidth =  linewidth,label=name[2]),\n",
    "\n",
    "        mlines.Line2D([], [], color=linec[1], marker=marker[1], linestyle=ls[1], linewidth = linewidth,label=name[1]),\n",
    "         mlines.Line2D([], [], color=linec[4], linestyle=ls[4],marker=marker[4],linewidth =  linewidth, label=name[4]),\n",
    "\n",
    "\n",
    "        mlines.Line2D([], [], color=linec[3], linestyle=ls[3],marker=marker[3],linewidth =  linewidth, label=name[3]),\n",
    "\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles=custom_lines,frameon = False,fontsize=11,bbox_to_anchor=(1, 0.99), loc='lower right', ncol=3, borderaxespad=0.05, handletextpad = 0.2, columnspacing = 0.4, labelspacing=0.2)\n",
    "    max_=0\n",
    "    for i in delay:\n",
    "        print(np.mean(i),max(i),end=' ')\n",
    "        max_=max(max_,max(i))\n",
    "#     ax.legend(loc='upper center',fontsize=12)\n",
    "#     ax.legend(frameon = False,fontsize=11,bbox_to_anchor=(1, 0.99), loc='lower right', ncol=3, borderaxespad=0.05, handletextpad = 0.2, columnspacing = 0.4, labelspacing=0.2)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    ax.set_ylabel('CDF',size=18)\n",
    "    ax.set_xlabel('Delay inflation(%)',size=18)\n",
    "    plt.xlim(0,max_+10)\n",
    "    plt.ylim(0,1)\n",
    "#     ax.set_xticklabels([10],rotation=45,size=12)\n",
    "    plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/{risk_country}_{constellation}_di.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "'''draw accuracy all'''\n",
    "#     fig , ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "#     custom_x = np.arange(4) * 2\n",
    "#     name = ['Alibi', r'STAR,$\\theta$=1',r'STAR,$\\theta$=2', r'STAR,$\\theta$=3']\n",
    "# #     name=['Cayey-Biratnagar','Azogues-Batang Kali','Huancavelica-Wiang Phang Kham','Centla-Krong Poi Pet','SAN Tomas-Vinh','La Asuncion-Seri Begawan']#['Monte Llano-Nepal','Ecuador-Malaysia','Colcabamba-Chiang Rai','Centla Municipality-Poipet','SAN Tomas-Ancheng','Suriname-Phnom Penh']\n",
    "# #     #name=['ML-NP','EC-MY','CO-CR','CM-PO','ST-AN','UNE-LS']#'SR-PNH']\n",
    "# #     name=['CP1','CP2','CP3','CP4','CP5','CP6']\n",
    "#     hatch_par = ['/', '', '|', '-', '+', 'x', 'o', 'O', '.', '*']\n",
    "#     bar_width = 0.8#total_width / n\n",
    "#     star_result0_300=[]\n",
    "#     star_result1_300=[]\n",
    "#     star_result2_300=[]\n",
    "#     star_result0_600=[]\n",
    "#     star_result1_600=[]\n",
    "#     star_result2_600=[]\n",
    "#     data0,data1=[],[]\n",
    "#     if risk_country=='Egypt':\n",
    "#         alibi_result_300=copy.deepcopy(alibi_300_E)\n",
    "#         alibi_result_600=copy.deepcopy(alibi_600_E)\n",
    "#         if constellation=='Starlink1':\n",
    "#             alibi_result_600fp=alibi_result_600[0]\n",
    "#             alibi_result_300fp=alibi_result_300[0]\n",
    "#             alibi_result_600fn=alibi_result_600[1]\n",
    "#             alibi_result_300fn=alibi_result_300[1]\n",
    "#             for ind in range(len(alibi_result_300fp)):\n",
    "#                 alibi_result_300fp[ind]=1-alibi_result_300fp[ind]\n",
    "#                 alibi_result_600fp[ind]=1-alibi_result_600fp[ind]\n",
    "#                 alibi_result_300fn[ind]=1-alibi_result_300fn[ind]\n",
    "#                 alibi_result_600fn[ind]=1-alibi_result_600fn[ind]\n",
    "                \n",
    "#         data0=[alibi_result_600fp,alibi_result_300fp,1]\n",
    "#         data1=[alibi_result_600fn,alibi_result_300fn,1]\n",
    "#     else:\n",
    "#         alibi_result_300=copy.deepcopy(alibi_300_K)\n",
    "#         alibi_result_600=copy.deepcopy(alibi_600_K)\n",
    "#         if constellation=='Starlink1':\n",
    "#             alibi_result_600fp=alibi_result_600[0]\n",
    "#             alibi_result_300fp=alibi_result_300[0]\n",
    "#             alibi_result_600fn=alibi_result_600[1]\n",
    "#             alibi_result_300fn=alibi_result_300[1]\n",
    "#             for ind in range(len(alibi_result_300fp)):\n",
    "#                 alibi_result_300fp[ind]=1-alibi_result_300fp[ind]\n",
    "#                 alibi_result_600fp[ind]=1-alibi_result_600fp[ind]\n",
    "#                 alibi_result_300fn[ind]=1-alibi_result_300fn[ind]\n",
    "#                 alibi_result_600fn[ind]=1-alibi_result_600fn[ind]\n",
    "#         data0=[alibi_result_600fp,alibi_result_300fp,1]\n",
    "#         data1=[alibi_result_600fn,alibi_result_300fn,1]        \n",
    "# #             star_result0_300=star_300_E_st[0]\n",
    "# #             star_result1_300=star_300_E_st[1]\n",
    "# #             star_result2_300=star_300_E_st[2]\n",
    "# #             star_result0_600=star_600_E_st[0]\n",
    "# #             star_result1_600=star_600_E_st[1]\n",
    "# #             star_result2_600=star_600_E_st[2]\n",
    "#     else:\n",
    "        \n",
    "#         alibi_result_300=copy.deepcopy(alibi_300_K)\n",
    "#         alibi_result_600=copy.deepcopy(alibi_600_K)\n",
    "#         if constellation=='Starlink1':\n",
    "#             star_result0_300=star_300_K_st[0]\n",
    "#             star_result1_300=star_300_K_st[1]\n",
    "#             star_result2_300=star_300_K_st[2]\n",
    "#             star_result0_600=star_600_K_st[0]\n",
    "#             star_result1_600=star_600_K_st[1]\n",
    "#             star_result2_600=star_600_K_st[2]\n",
    "# #     if FP:\n",
    "# #         alibi_result_600=alibi_result_600[0]\n",
    "# #         alibi_result_300=alibi_result_300[0]\n",
    "# #         for ind in range(len(alibi_result_300)):\n",
    "# #             alibi_result_300[ind]=1-alibi_result_300[ind]\n",
    "# #             alibi_result_600[ind]=1-alibi_result_600[ind]\n",
    "# #         star_600_0,star_600_1,star_600_2=[],[],[]\n",
    "# #         star_300_0,star_300_1,star_300_2=[],[],[]\n",
    "# #         for ind in range(len(star_result0_600[1])):\n",
    "# #             if math.isnan(star_result0_600[1][ind]):continue\n",
    "# #             star_600_0.append(1-star_result0_600[1][ind])\n",
    "# #             if math.isnan(star_result1_600[1][ind]):continue\n",
    "# #             star_600_1.append(1-star_result1_600[1][ind])\n",
    "# #             if math.isnan(star_result2_600[1][ind]):continue\n",
    "# #             star_600_2.append(1-star_result2_600[1][ind])\n",
    "# #             if math.isnan(star_result0_300[1][ind]):continue\n",
    "# #             star_300_0.append(1-star_result0_300[1][ind])\n",
    "# #             if math.isnan(star_result1_300[1][ind]):continue\n",
    "# #             star_300_1.append(1-star_result1_300[1][ind])\n",
    "# #             if math.isnan(star_result2_300[1][ind]):continue\n",
    "# #             star_300_2.append(1-star_result2_300[1][ind])\n",
    "# #         data1=[np.mean(alibi_result_600),1,1,1]\n",
    "# #         data2=[np.mean(alibi_result_300),1,1,1]\n",
    "\n",
    "# # #         d1_errors=[[min(alibi_result_600),max(alibi_result_600)],[min(star_600_0),max(star_600_0)],[min(star_600_1),max(star_600_1)],[min(star_600_2),max(star_600_2)]]\n",
    "# # #         d2_errors=[[min(alibi_result_300),max(alibi_result_300)],[min(star_300_0),max(star_300_0)],[min(star_300_1),max(star_300_1)],[min(star_300_2),max(star_300_2)]]\n",
    "# # #         data1=[np.mean(alibi_result_600),np.mean(star_600_0),np.mean(star_600_1),np.mean(star_600_2)]\n",
    "# # #         data2=[np.mean(alibi_result_300),np.mean(star_300_0),np.mean(star_300_1),np.mean(star_300_2)]\n",
    "# #     else:\n",
    "# #         alibi_result_600=alibi_result_600[1]\n",
    "# #         alibi_result_300=alibi_result_300[1]\n",
    "# #         for ind in range(len(alibi_result_300)):\n",
    "# #             alibi_result_300[ind]=1-alibi_result_300[ind]\n",
    "# #             alibi_result_600[ind]=1-alibi_result_600[ind]\n",
    "# #         star_600_0,star_600_1,star_600_2=[],[],[]\n",
    "# #         star_300_0,star_300_1,star_300_2=[],[],[]\n",
    "# #         for ind in range(len(star_result0_600[1])):\n",
    "# #             if math.isnan(star_result0_600[1][ind]):continue\n",
    "# #             star_600_0.append(1-star_result0_600[1][ind])\n",
    "# #             if math.isnan(star_result1_600[1][ind]):continue\n",
    "# #             star_600_1.append(1-star_result1_600[1][ind])\n",
    "# #             if math.isnan(star_result2_600[1][ind]):continue\n",
    "# #             star_600_2.append(1-star_result2_600[1][ind])\n",
    "# #             if math.isnan(star_result0_300[1][ind]):continue\n",
    "# #             star_300_0.append(1-star_result0_300[1][ind])\n",
    "# #             if math.isnan(star_result1_300[1][ind]):continue\n",
    "# #             star_300_1.append(1-star_result1_300[1][ind])\n",
    "# #             if math.isnan(star_result2_300[1][ind]):continue\n",
    "# #             star_300_2.append(1-star_result2_300[1][ind])\n",
    "# #         data1=[np.mean(alibi_result_600),1,1,1]\n",
    "# #         data2=[np.mean(alibi_result_300),1,1,1]\n",
    "# #         data1=[np.mean(alibi_result_600),np.mean(star_600_0),np.mean(star_600_1),np.mean(star_600_2)]\n",
    "# #         data2=[np.mean(alibi_result_300),np.mean(star_300_0),np.mean(star_300_1),np.mean(star_300_2)]\n",
    "#     data1_middles = custom_x - bar_width / 2\n",
    "#     data2_middles = custom_x + bar_width/2\n",
    "#     print(data1_middles,data2_middles)\n",
    "#     print(min(alibi_result_300),np.mean(alibi_result_300),max(alibi_result_300))\n",
    "#     print(min(alibi_result_600),np.mean(alibi_result_600),max(alibi_result_600))\n",
    "#     print(min(star_600_0),np.mean(star_600_0),max(star_600_0))\n",
    "#     print(min(star_600_1),np.mean(star_600_1),max(star_600_1))\n",
    "#     print(min(star_600_2),np.mean(star_600_2),max(star_600_2))\n",
    "#     print(min(star_300_0),np.mean(star_300_0),max(star_300_0))\n",
    "#     print(min(star_300_1),np.mean(star_300_1),max(star_300_1))\n",
    "#     print(min(star_300_2),np.mean(star_300_2),max(star_300_2))\n",
    "#     rects1 = ax.bar(custom_x - bar_width/2, data1, bar_width, label='W=600s',hatch=hatch_par[0], color='lightblue')\n",
    "#     rects2 = ax.bar(custom_x + bar_width/2, data2, bar_width, label='W=300s',hatch=hatch_par[1], color='orange')\n",
    "#     ind=0\n",
    "#     ax.plot([data1_middles[ind], data1_middles[ind]], [min(alibi_result_600), max(alibi_result_600)],marker='_', color='black')\n",
    "#     ax.plot([data2_middles[ind], data2_middles[ind]], [min(alibi_result_300), max(alibi_result_300)],marker='_', color='black')\n",
    "#     ind=1\n",
    "#     for ind in range(1,len(name)):\n",
    "#         ax.plot([data1_middles[ind], data1_middles[ind]], [1,1],marker='_', color='black')\n",
    "#         ax.plot([data2_middles[ind], data2_middles[ind]], [1,1],marker='_', color='black')\n",
    "# #     ax.plot([data1_middles[ind], data1_middles[ind]], [min(star_600_0), max(star_600_0)],marker='_', color='black')\n",
    "# #     ax.plot([data2_middles[ind], data2_middles[ind]], [min(star_300_0), max(star_300_0)],marker='_', color='black')   \n",
    "# #     ind=2\n",
    "# #     ax.plot([data1_middles[ind], data1_middles[ind]], [min(star_600_1), max(star_600_1)],marker='_', color='black')\n",
    "# #     ax.plot([data2_middles[ind], data2_middles[ind]], [min(star_300_1), max(star_300_1)],marker='_', color='black')\n",
    "# #     ind=3\n",
    "# #     ax.plot([data1_middles[ind], data1_middles[ind]], [min(star_600_2), max(star_600_2)],marker='_', color='black')\n",
    "# #     ax.plot([data2_middles[ind], data2_middles[ind]], [min(star_300_2), max(star_300_2)],marker='_', color='black')\n",
    "#     ax.set_ylabel('Accuracy(%)',size=18)\n",
    "#     #ax.set_title('Values by custom group positions')\n",
    "#     ax.set_xticks(custom_x)\n",
    "#     ax.set_xticklabels([i for i in name],rotation=45,size=12)\n",
    "#     ax.legend(frameon = False,fontsize=11,bbox_to_anchor=(1, 0.99), loc='lower right', ncol=2, borderaxespad=0.05, handletextpad = 0.2, columnspacing = 0.4, labelspacing=0.2)\n",
    "\n",
    "# #     plt.savefig(f'/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/{risk_country}_FP_{FP}.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "eva(risk_country='Korea',constellation='Starlink1',FP=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''draw the Earth'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "def plot_globe_earth():\n",
    "    # set projection type as Orthographic，simulate earth sphere view\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Orthographic(central_longitude=0, central_latitude=0))\n",
    "    \n",
    "    # add map features\n",
    "    ax.add_feature(cfeature.OCEAN, zorder=0)  # add oceans\n",
    "    ax.add_feature(cfeature.LAND, zorder=0)   # add lands\n",
    "    ax.add_feature(cfeature.COASTLINE, zorder=1)  # add coastlines\n",
    "   # ax.add_feature(cfeature.BORDERS, linestyle=':', zorder=1)  #add the country borders\n",
    "    #ax.add_feature(cfeature.LAKES, zorder=1)  # add lakes\n",
    "    #ax.add_feature(cfeature.RIVERS, zorder=1)  # add rivers\n",
    "    \n",
    "    # set grid lines\n",
    "    #gl = ax.gridlines(draw_labels=False, linewidth=1, color='gray')\n",
    "#     gl.top_labels = False\n",
    "#     gl.right_labels = False\n",
    "    plt.savefig('/data/chenwei/research3/data/StarVeri_ICNP/eva_fig/globe_earth.svg', dpi=300)\n",
    "    # show image\n",
    "    plt.show()\n",
    "\n",
    "plot_globe_earth()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
